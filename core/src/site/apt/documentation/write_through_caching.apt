 ---
 Write-through and Write-behind Caching with the CacheWriter
 ---

{Write-through and Write-behind Caching with the CacheWriter}

    new-in-2 Write-through caching is a caching pattern where writes to the cache cause writes to an underlying resource. The cache acts as a facade
    to the underlying resource. With this pattern, it often makes sense to read through the cache too.

    Write-behind caching uses the same client API, however the write happens asynchronously.

    Ehcache-2.0 introduces write-through caching.

    While any resource can sit behind the facade of a w-t cache, such as a file system, or a web service client, the common one is a database.
     To simplify the discussion, we will use database as the example resource.

* Potential Benefits of Write-Behind

    The big potential benefit of write-behind is database offload. This can be achieved in a number of ways:

     * time shifting - moving writes to a specific time or time interval. For example writes could be batched up and written overnight,
     or at 5 minutes past the hour, so as to avoid periods of peak contention.

     * rate limiting - spreading writes out to flatten peaks. Say a Point of Sale network has an end-of-day procedure where data gets
     written up to a central server. All POS nodes in the same time zone will write all at once. A very large peak will occur. Using rate
     limiting, writes could be limited to 100 TPS, and the queue of writes are whittled down over several hours

     * conflation - consolidation writes so as to result in fewer transactions. Say there is an amount in a database row whic is updated by 5
      writes, incrementing it from 10 to 20 to 31 to 40 to 45. Using conflation the 5 transactions are replaced by one which simply updates
      the value from 10 to 45.

     These benefits must be weighed against the limitations and constraints imposed.

* Limitations & Constraints of Write-Behind

** Transaction Boundaries

   If the cache participates in a JTA transaction (ehcache-2.0 and higher) (i.e. it is an XAResource) then the Cache can be made  consistent with the
   database as the write to the database and commit or rollback happens with the transaction boundary.

    In write-behind, the write to the resource happens after the write to the cache. The transaction boundary is the write to the, not
     the write behind. In write-through commit can get called and bot the Cache and the underlying resource, e.g. the database can get
     committed at once.

    Because the database is being written to outside of the transaction, there is always a risk that a failure on the eventual write
    will occur. While this can be mitigated with retry counts and delays, compensating actions may be required.



** Time delay

    The obvious implication of asynchronous writes is that there is a delay between when the cache is updated and when the database
    is updated. This introduces an inconsistency between the cache and the database, where the cache holds the correct value and the
    database will be eventually consistent with the cache.

    A read against the database will result in incorrect data being loaded.


** Applications Tolerant of Inconsistency

    The application must be tolerant of this inconsistency, as per the following are examples:

     * The database is logging transactions and only appends are done.

     * Reading is done by a part of the application that does not write, so there is no way that data can be corrupted. The application
     is tolerant of delays. E.g. a news application where the reader displays the articles that are written.

    Note that in practice, if other applications are writing to the database, then a cache can often be inconsistent with the database.

**  Node time synchronisation

    Ideally node times should be synchronised. The write-behind queue is generally written to the underlying resource in timestamp order, based
    on the timestamp of the cache operation, although there is no guaranteed ordering.

    The ordering will be more consistent if all nodes are using the same time. This can easily be achieved by configuring
     your system clock to syncrhonise with a time authority using Network Time Protocol.


* Using a combined Read-Through and Write-Behind Cache

    For applications that are not tolerant of inconsistency, the simplest solution is for the application to always read through
    the same cache that it writes through. Provided all database writes are through the cache, consistency is guaranteed. And in the
    distributed caching scenario, using Terracotta clustering extends the same guarantee to the cluster.

    If using transactions, the cache is the XAResource, and a commit is a commit to the cache.

    The cache effectively becomes the System Of Record ("SOR"). Terracotta provides
    HA and durability and can easily act as the SOR. The database then becomes a backup to the SOR.

    There are some practical problems that come up when using this approach: caching of a partial dataset and expiry and eviction limitations


** Lazy Loading

    The question arises: Does the entire data set need to be loaded in the cache on startup? The answer is no, because a read-through cache
    uses a <<<CacheLoader>>> which loads data into the cache on demand. In this way the cache be populated lazily.


** Caching of a Partial Dataset

   If the entire dataset cannot fit in the cache, then some reads will miss the cache and fall through to the <<<CacheLoader>>> which will
   in turn hit the database. If a write has occurred but has not yet hit the database due to write-behind, then the database will be inconsistent.

   The simplest solution is to ensure that the entire dataset is in the cache. This then places some implications on cache configuration
   in the areas of expiry and eviction.

*** Eviction

   Eviction occurs when the maximum elements for the cache have been exceeded. Ensure that the <<<maxElementsInMemory>>> and, if using the DiskStore
    or Terracotta clustering, the <<<maxElementsOnDisk>>> exceeds the required size, so that eviction does not not occur.

*** Expiry

   Even if all of the dataset can fit in the cache, it could be evicted if Elements expire. Accordingly, both <<<timeToLive>>> and
       <<<timeToIlde>>> should be set to eternal to prevent this from happening.

*   Ehcache Versions

    Both Ehcache standalone and with Terracotta Server Array (Ehcache EX and FX) are supported.

**  Ehcache DX (Standalone Ehcache)

    The write-behind queue is stored locally in memory. It supports all configuration options, but any data in the queue
    will be lost on JVM shutdown.

**  Ehcache EX and FX

*** Durable HA write-behind Queue

    EX and FX when used with the Terracotta Server Array will store the queue on the Terracotta Server Array and can thus be configured
     for durability and HA. The data is still kept in the originating node for performance.

*** Cluster wide queue processing

    In a cluster each node will have a <<<CacheWriter>>> configured. These will process their local work, but if there is no local
    work, they will poll the other nodes to see if there is outstanding work and process part of that work.

    This means that workload is balanced across the cluster, and that the write-behind queue will be serviced as long as there is one
    Ehcache L1 instance in the cluster.

* Configuration

    There are many configuration options. See the <<<CacheWriterConfiguration>>> for properties that may be set and their effect.

    Below is an example of how to configure the cache writer in XML:

---
    <cache name="cacheName" eternal="false" maxElementsInMemory="1000" overflowToDisk="false">
        <cacheWriter writeMode="write_behind" maxWriteDelay="8" rateLimitPerSecond="5"
                     writeCoalescing="true" writeBatching="true" writeBatchSize="20"
                     retryAttempts="2" retryAttemptDelaySeconds="2">
            <cacheWriterFactory class="com.company.MyCacheWriterFactory"
                                properties="just.some.property=test; another.property=test2" propertySeparator=";"/>
        </cacheWriter>
    </cache>

Further examples:

  <cache name="writeThroughCache1" eternal="false" maxElementsInMemory="1000" overflowToDisk="false"/>

  <cache name="writeThroughCache2" eternal="false" maxElementsInMemory="1000" overflowToDisk="false">
      <cacheWriter/>
  </cache>

  <cache name="writeThroughCache3" eternal="false" maxElementsInMemory="1000" overflowToDisk="false">
      <cacheWriter writeMode="write_through" notifyListenersOnException="true" maxWriteDelay="30"
                   rateLimitPerSecond="10" writeCoalescing="true" writeBatching="true" writeBatchSize="8"
                   retryAttempts="20" retryAttemptDelaySeconds="60"/>
  </cache>

  <cache name="writeThroughCache4" eternal="false" maxElementsInMemory="1000" overflowToDisk="false">
      <cacheWriter writeMode="write_through" notifyListenersOnException="false" maxWriteDelay="0"
                   rateLimitPerSecond="0" writeCoalescing="false" writeBatching="false" writeBatchSize="1"
                   retryAttempts="0" retryAttemptDelaySeconds="0">
          <cacheWriterFactory class="net.sf.ehcache.writer.WriteThroughTestCacheWriterFactory"/>
      </cacheWriter>
  </cache>

  <cache name="writeBehindCache5" eternal="false" maxElementsInMemory="1000" overflowToDisk="false">
      <cacheWriter writeMode="write-behind" notifyListenersOnException="true" maxWriteDelay="8" rateLimitPerSecond="5"
                   writeCoalescing="true" writeBatching="false" writeBatchSize="20"
                   retryAttempts="2" retryAttemptDelaySeconds="2">
          <cacheWriterFactory class="net.sf.ehcache.writer.WriteThroughTestCacheWriterFactory"
                              properties="just.some.property=test; another.property=test2" propertySeparator=";"/>
      </cacheWriter>
  </cache>

---

    This configuration can also be achieved through the <<<Cache>>> constructor in Java, like this:

---
    Cache cache = new Cache(
        new CacheConfiguration("cacheName", 10)
            .cacheWriter(new CacheWriterConfiguration()
                .writeMode(CacheWriterConfiguration.WriteMode.WRITE_BEHIND)
                .maxWriteDelay(8)
                .rateLimitPerSecond(5)
                .writeCoalescing(true)
                .writeBatching(true)
                .writeBatchSize(20)
                .retryAttempts(2)
                .retryAttemptDelaySeconds(2)
                .cacheWriterFactory(new CacheWriterConfiguration.CacheWriterFactoryConfiguration()
                    .className("com.company.MyCacheWriterFactory")
                    .properties("just.some.property=test; another.property=test2")
                    .propertySeparator(";"))));
---

    Instead of relying on a <<<CacheWriterFactoryConfiguration>> to create a <<<CacheWriter>>>, it's also possible to explicitly
    register a <<<CacheWriter>>> instance from within Java code. This allows you to refer to local resources like database
    connections or file handles.

---
    Cache cache = manager.getCache("cacheName");
    MyCacheWriter writer = new MyCacheWriter(jdbcConnection);
    cache.registerCacheWriter(writer);
---


** Configuration Attributes

   The CacheWriterFactory supports the following attributes:

*** All modes

   *  write-mode [write-through | write-behind] - whether to run in write-behind or write-through mode. The default is write-through.


*** write-through mode only

   *  notifyListenersOnException - whether to notify listeners when a an exception occurs on a storer operation. Defaults to false.


*** write-behind mode only


     *  maxWriteDelaySeconds        the maximum number of seconds to wait before writing behind. Defaults to 0. If set to a value
                                      greater than 0, it permits operations to build up in the queue to enable effective coalescing
                                      and batching optimisations.

     *  rateLimitPerSecond          the maximum number of store operations to allow per second. If writeBatching is enabled,

     *  writeCoalescing             whether to use write coalescing. Defaults to false. If set to true, if multiple operations
                                      on the same key are present in the write-behind queue, only the latest write is done, as the
                                      others are redundant. This can dramatically reduce load on the underlying resource.

     *  writeBatching               whether to batch write operations. Defaults to false. If set to true, storeAll and deleteAll
                                      will be called rather than store and delete being called for each key. Resources such as databases
                                      can perform more efficiently if updates are batched, thus reducing load.

     *  writeBatchSize              the number of operations to include in each batch. Defaults to 1. If there are less entries in the
                                      write-behind queue than the batch size, the queue length size is used. Note that batching is split
                                      across operations. So, if the batch size is 10 and there were 5 puts and 5 deletes, then the
                                      CacheWriter will be invoked then, not after 10 puts and 10 deletes.

     *  retryAttempts               the number of times to attempt. Defaults to 1.

     *  retryAttemptDelaySeconds    the number of seconds to wait before retrying.


* API

    CacheLoaders are exposed for API use through the <<<cache.getWithLoader(...)>>> method. CacheWriters are exposed with
    <<<cache.putWithWriter(...)>>> and <<<cache.removeWithWriter(...)>>> methods.

    For example, following is the method signature for <<<cache.putWithWriter(...)>>>.

---
    /**
     * Put an element in the cache writing through a CacheWriter. If no CacheWriter has been set for the cache,
     * then this method has the same effect as cache.put().
     * <p/>
     * Resets the access statistics on the element, which would be the case if it has previously been
     * gotten from a cache, and is now being put back.
     * <p/>
     * Also notifies the CacheEventListener, if the writer operation succeeds, that:
     * <ul>
     * <li>the element was put, but only if the Element was actually put.
     * <li>if the element exists in the cache, that an update has occurred, even if the element would be expired
     * if it was requested
     * </ul>
     *
     * @param element An object. If Serializable it can fully participate in replication and the DiskStore.
     * @throws IllegalStateException    if the cache is not {@link net.sf.ehcache.Status#STATUS_ALIVE}
     * @throws IllegalArgumentException if the element is null
     * @throws CacheException
     */
    void putWithWriter(Element element) throws IllegalArgumentException, IllegalStateException, CacheException;

---

    See the Cache JavaDoc for the complete API.


* SPI

    The Ehcache write-through SPI is the <<<CacheWriter>>> interface. Implementers perform writes to the underlying resource
    in their implementation.

---
/**
 * A CacheWriter is an interface used for write-through and write-behind caching to a underlying resource.
 * <p/>
 * If configured for a cache, CacheWriter's methods will be called on a cache operation. A cache put will cause a CacheWriter write
 * and a cache remove will cause a writer delete.
 * <p>
 * Implementers should create an implementation which handles storing and deleting to an underlying resource.
 * </p>
 * <h4>Write-Through</h4>
 * In write-through mode, the cache operation will occur and the writer operation will occur before CacheEventListeners are notified. If
 * the write operation fails an exception will be thrown. This can result in a cache which is inconsistent with the underlying resource.
 * To avoid this, the cache and the underlying resource should be configured to participate in a transaction. In the event of a failure
 * a rollback can return all components to a consistent state.
 * <p/>
 * <h4>Write-Behind</h4>
 * In write-behind mode, writes are written to a write-behind queue. They are written by a separate execution thread in a configurable
 * way. When used with Terracotta Server Array, the queue is highly available. In addition any node in the cluster may perform the
 * write-behind operations.
 * <p/>
 * <h4>Creation and Configuration</h4>
 * CacheWriters can be created using the CacheWriterFactory.
 * <p/>
 * The manner upon which a CacheWriter is actually called is determined by the {@link net.sf.ehcache.config.CacheWriterConfiguration} that is set up for cache
 * that is using the CacheWriter.
 * <p/>
 * See the CacheWriter chapter in the documentation for more information on how to use writers.
 *
 * @author Greg Luck
 * @author Geert Bevin
 * @version $Id: $
 */
public interface CacheWriter {

    /**
     * Creates a clone of this writer. This method will only be called by ehcache before a
     * cache is initialized.
     * <p/>
     * Implementations should throw CloneNotSupportedException if they do not support clone
     * but that will stop them from being used with defaultCache.
     *
     * @return a clone
     * @throws CloneNotSupportedException if the extension could not be cloned.
     */
    public CacheWriter clone(Ehcache cache) throws CloneNotSupportedException;


    /**
     * Notifies writer to initialise themselves.
     * <p/>
     * This method is called during the Cache's initialise method after it has changed it's
     * status to alive. Cache operations are legal in this method.
     *
     * @throws net.sf.ehcache.CacheException
     */
    void init();

    /**
     * Providers may be doing all sorts of exotic things and need to be able to clean up on
     * dispose.
     * <p/>
     * Cache operations are illegal when this method is called. The cache itself is partly
     * disposed when this method is called.
     */
    void dispose() throws net.sf.ehcache.CacheException;

    /**
     * Write the specified value under the specified key to the underlying store.
     * This method is intended to support both key/value creation and value update for a specific key.
     *
     * @param element the element to be written
     */
    void write(Element element) throws CacheException;

    /**
     * Write the specified Elements to the underlying store. This method is intended to support both insert and update.
     * If this operation fails (by throwing an exception) after a partial success,
     * the convention is that entries which have been written successfully are to be removed from the specified mapEntries,
     * indicating that the write operation for the entries left in the map has failed or has not been attempted.
     *
     * @param elements the Elements to be written
     */
    void writeAll(Collection<Element> elements) throws CacheException;


    /**
     * Remove the key and associated data from the store
     *
     * @param key the key whose mapping will be removed
     */
    void delete(Object key) throws CacheException;


    /**
     * Remove data and keys from the underlying store for the given collection of keys, if present. If this operation fails
     * (by throwing an exception) after a partial success, the convention is that keys which have been erased successfully
     * are to be removed from the specified keys, indicating that the erase operation for the keys left in the collection
     * has failed or has not been attempted.
     *
     * @param keys the keys whose mappings will be removed
     */
    void deleteAll(Collection<Object> keys) throws CacheException;
}
---

