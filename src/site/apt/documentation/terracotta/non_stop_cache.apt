 ---
 NonStopCache
 ---

{NonStopCache}



---
Nonstop minimal config:

<cache name="cacheName" maxElementsInMemory="10000" eternal="true" overflowToDisk="false">
<terracotta>
		<nonstop />
	</terracotta>
</cache>

Nonstop default values:

<cache name="four" maxElementsInMemory="10000" eternal="true"
	overflowToDisk="false">
	<terracotta clustered="false">
		<nonstop enabled="true" immediateTimeout="true" timeoutMillis="5000">
			<timeoutBehavior type="exception" />       null | localReads
		</nonstop>
	</terracotta>
</cache>

Rejoin Config:
<ehcache name="basic-cache-test">
	<defaultCache maxElementsInMemory="10000" eternal="true"
		overflowToDisk="false" />
	<cache name="test" maxElementsInMemory="10000" eternal="true"
		overflowToDisk="false">
		<terracotta>
			<nonstop />
		</terracotta>
	</cache>
	<terracottaConfig rejoin="true" url="localhost:9510" />
</ehcache>

Rejoin Event:
net.sf.ehcache.cluster.ClusterTopologyListener {
    void clusterRejoined(ClusterNode oldNode, ClusterNode newNode);
}
---


Rejoin happens when reconnect has failed. The L1 has been connected. It will rejoin as a new client.
Your puts are blocked

L2 kicks the L1 out li.l2reconnect.timeout.millis

If the socket closes the L1 is kicked out.

By default reconnect is turned off. If you set it to true     ????

There is a pre-crash L1 membership.

Until the reconnectWindow is exceeded when you will not be allowed back in. The timeout is 120s.

When the L2 says an L1 cannot reconnect this will trigger an attempt to rejoin.

Reconnect is in the product docs.




l2.l1reconnect.timeout.millis controls when

The l2s talk to each other so the other l2

Until reconnect fails you continue to hold locks (if running in strict mode).

When reconnect fails, rejoin will attempt to join the L2. When it joins, it will join as a new L1. Any data
held in the local cache is discarded. All locks are discarded. This is transparent to the end user.

Prior to an L1

Rejoin if set to true, will continously try to rejoin.     rejoin=true is the default.

Prior to this an L1 could not reconnect without restarting the app server with the L1 in it.





    <<<NonStopCache>>> is a {{{./cache_decorators.html}decorated cache}} which provides SLA level control
    features for your cache. It is difficult to rely on your, disk, Database (For write-through), distribution
	mechanism etc  all being tuned perfectly to provide you the timing characteristics/semantics your application needs.
	Non-stop cache allows a developer to take a layered approach to SLAs. Each portion of an application can specify
	the timing characteristics it needs for a given cache. No matter what happens beneath the Non-stop cache decorator those
	semantics are maintained.

    Usecases include:

    * Set timeouts on cache operations.

      For example, say you use the cache rather than a mainframe. The SLA calls for 3 seconds.
      There is a temporary network interruption which stops Terracotta responding to a cache request. With the timeout
      you can return after 3 seconds. The lookup is then done against the mainframe. This could also be useful for
      write-through, writes to disk or synchronous writes.

    * Automatically respond to cluster topology events to take a pre-configured action.

	* You're using a disk based cache and your hard drive becomes unavailable. If you are using the Non-stop cache decorator
	  you can control whether operations timeout, or drop back to noop, or even switch over to an in memory only cache.

	* You're using a write-through cache and your DB hangs. Use your Non-stop cache decorator to keep it from hanging your entire
	  Application Server.

	* You have one cache that is accessed for multiple functions. For some of those functions you want operations to timeout after
	  5 seconds and for others you want 20 seconds. You can have multiple decorators on the same cache with the different semantics
      defined.









*   Creating a NonStopCache

**  Programmatically

---
    Cache cache = cacheManager.getCache("existingUndecoratedCache");
    NonStopCache nonStopCache = new NonStopCache(cache, newName);
    cacheManager.addDecoratedCache(nonStopCache);  //adds a decorated Ehcache
---

     Creating a NonStopCache does not put itself to the CacheManager. It is optional and up to the app to put the decorated
     NonStopCache back in the CacheManager. Putting the NonStopCache back in the CacheManger makes it available to other
     areas of the app where the CacheManager is accessible.

     If the NonStopCache has the same name as the cache its decorating,
     <<<CacheManager.replaceCacheWithDecoratedCache(Ehcache ehcache, Ehcache decoratedCache)>>> should be used instead of
     using <<<CacheManager.addDecoratedCache(Ehcache decoratedCache)>>> as shown above.

     If added to the CacheManager, it can be accessed per the following:

---
    Ehcache nonStopCache = cacheManager.getEhcache(newName);
---

**  In ehcache.xml

    It can be configured in ehcache.xml using the "cacheDecoratorFactory" element. You can specify a factory to create decorated caches and
    <<<net.sf.ehcache.constructs.nonstop.NonStopCacheDecoratorFactory>>> is available in the nonstopcache module itself.

---

    <cache name="sample/DistributedCache3"
           maxElementsInMemory="10"
           eternal="false"
           timeToIdleSeconds="100"
           timeToLiveSeconds="100"
           overflowToDisk="true">
        <cacheDecoratorFactory
                class="net.sf.ehcache.constructs.nonstop.NonStopCacheDecoratorFactory"
                properties="name=nonStopCacheName, timeoutMillis=3000, timeoutBehavior=noop ..."/>
    </cache>
---

    It is mandatory to specify properties when configuring NonStopCacheDecoratorFactory in ehcache.xml. List of all the properties supported by
    NonStopCacheDecoratorFactory and corresponding valid values are:

       name             - any string name for the NonStopCache. This property is mandatory.

       timeoutMillis    - Any number for use as the timeout time in milliseconds before timing out for any operation. After the operation times out, behavior as
                          specified by timeoutBehavior happens. This property is optional and uses a default value if not specified. This should be set to your desired
                          SLA level. The default value is 10000ms.

       timeoutBehavior  - {exception | noop | localReads}. This property is optional and uses a default value if not specified. The default is exception.

       immediateTimeout - {true | false}. Default is true.


*   How it knows about Terracotta Cluster Events

    Behind the scenes, the TerracottaAwareCache constructor looks up the Terracotta cluster
    and registers a <<<ClusterTopologyListener>>> which calls back on certain cluster events.

---
   CacheCluster cacheCluster = cacheManager.getCluster(ClusterScheme.TERRACOTTA);
   cacheCluster.addTopologyListener(yourListener);
---

    In particular it is interested in the <<<clusterOffline>>> and <<<clusterOnline>>> events.

*   Configuration Options

**  Timeout Configuration

***   Setting Timeouts

    Set the <<<timeoutMillis>>> property. It applies to all cache operations (put, get, remove ...). After the time elapses the operation is aborted. For mutate
    operations (put, remove etc), it cannot be guaranteed whether the operation succeeded or not when the timeout happened.

    What happens on timeout depends on the value of <<<timeoutBehavior>>>, which can take the following values:

    <<<noop>>>        - gets return null. Mutating operations such as put and removed are ignored.

    <<<exception>>>   - An unchecked exception, <<<NonStopCacheException>>>, which is a subtype of <<<CacheException>>> will be thrown.

    <<<localReads>>>   - currently Terracotta only. Returns data if held locally in memory in response to gets. Mutating operations such as put and removed are ignored.

    NOTE: <<<localReads>>> behavior works only with <<<Cache>>> instances which are clustered using Terracotta. One obvious disadvantage is that it cannot be used to
    decorate unclustered Cache's. Another not so obvious disadvantage is that <<<localReads>>> cannot be used when decorating other already decorated Caches
    like <<<UnlockedReadsView>>>

***  ThreadPool Management

    The timeout feature uses a SEDA style approach which utilises an Executor thread pool. By default one NonStopCache is associated with one Executor thread pool
    (NonStopCacheExecutorService). The default NonStopCacheExecutorService has 10 threads, allowing 10 concurrent cache operations.

    Different NonStopCache's can use the same Executor thread pool if desired. It can be achieved by using the NonStopCache constructor that accepts the
    NonStopCacheExecutorService. You can specify your own thread pool size for each NonStopCacheExecutorService using the constructor that accepts <<<threadPoolSize>>>.

    The thread pool is shut down when the associated NonStopCache (or all of them, if multiple NonStopCache uses the same NonStopCacheExecutorService) is disposed.

**  Action on ClusterOffline Configuration

    The clusterOfflineEvent is thrown when the socket between the client and server is closed. Note that there is no way
    the cache has of knowing whether the interruption is transitory or permanent. For that reason it is recommended that it be
    used in conjunction with <<<timeoutMillis>>> so that short interruptions do not trigger this.

    In this version the only action which may be configured is <<<immediateTimeout>>>.

    If immediateTimeout is true, then cache operations will immediately timeout after a clusterOffline event has been received.


*** immediateTimeout

    The property <<<immediateTimeout>>> if set to true will cause the cache operations to act as if they have immediately timed out,
    without waiting the <<<timeoutMillis>>> value.

    What then happens depends on how <<<timeoutBehavior>>> is configured.

*** timeoutMillis

    The timeoutMillis

    Remember that if an L2 goes away you will get a clusterOffline event after the li.l2reconnect.timeout.millis. This is based on heartbeating
    between the L1-L2. This is essentially a network ping test. So timeoutMillis is meant to cover
    situations up to that timeout. Setting it higher than ?? has no effect, because a clusterOffline event will be received before the timemoutMillis
    takes effect.

    The general guide is SLA. If your SLA is a 5 second response, set this to 5 seconds. Then if a cache operation fails you will get an exception
    which gives you the possiblity to then call the SLA. You can catch the

    On the flip side what is the effect in your application on requests backing up. Before NIO application servers would allocate one thread per request.
    The danger was that you could get an OutOfMemoryError if requests backed up.

    In modern application servers there is a threadpool used to service requests. So the consequences of a back up are less dramatic.

    Some causes of timeouts are:

    * Full GC events.

    * Contention in the persistency layer in the Terracotta server

    *


*   {Download}

**  File

    Download {{{http://sourceforge.net/projects/ehcache/files/ehcache-nonstopcache}here}}.

**  Maven

    The code is in the ehcache-nonstopcache module in the Maven central repo.

    Add this snippet to your dependencies:

---

<dependency>
    <groupId>net.sf.ehcache</groupId>
    <artifactId>ehcache-nonstopcache</artifactId>
</dependency>
---

*   {Emerging API}

    This API is emerging. It is production quality and supported, but is a new API and may evolve over time.

**  More information

    {{{http://dsoguy.blogspot.com/2010/05/couple-minutes-with-non-stop-ehcache_07.html}A Couple Minutes With Non-Stop Ehcache}}.




New Nonstrict Mode
If any data is in te L1, then it will be available during the transition to the timeout. You always get stale data.




