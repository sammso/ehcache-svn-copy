 ---
 Off-heap Store
 ---

{BigMemory: Off-heap Store}

[images/big_memory.png]

%{toc|fromDepth=2|toDepth=3}

    Terracotta {{{http://www.terracotta.org/bigmemory?src=ehcache_off_heap_store}BigMemory}} is an add-on to Enterprise Ehcache
    that permits caches to use an additional type of memory store outside the object heap.

    This off-heap store, which is not subject to Java GC, is 100 times faster than the DiskStore and allows
    very large caches to be created (we have tested this up to 350GB).

    Because off-heap data is stored in bytes, there are two implications:

    * Only Serializable cache keys and values can be placed in the store, similar to DiskStore.

    * Serialization and deserialization take place on putting and getting from the store. This means that the
      off-heap store is slower in an absolute sense (around 10 times slower than the MemoryStore), but this
      theoretical difference disappears due to two effects:

      * the MemoryStore holds the hottest subset of data from the off-heap store, already in deserialized form

      * when the GC involved with larger heaps is taken into account, the off-heap store is faster on average

*   Configuration

**  Configuring caches to overflow to off-heap.

    Configuring a cache to use an off-heap store can be done either through XML or programmatically.

***  Declarative Configuration

    The following XML configuration creates an off-heap cache with an in-heap store (maxElementsInMemory)
    of 10,000 elements which overflow to a 1-gigabyte off-heap area.

---
    <?xml version="1.0" encoding="UTF-8"?>
    <ehcache updateCheck="false" monitoring="off"
             dynamicConfig="false">

        <defaultCache maxElementsInMemory="10000"
                      eternal="true"
                      memoryStoreEvictionPolicy="LRU"
                      statistics="false" />

        <cache name="sample-offheap-cache"
               maxElementsInMemory="10000"
               eternal="true"
               memoryStoreEvictionPolicy="LRU"
               overflowToOffHeap="true"
               maxMemoryOffHeap="1G"/>
    </ehcache>
---

    The configuration options are:

****  overflowToOffHeap

    Values may be true or false.

    When set to true, enables the cache to utilize off-heap memory
    storage to improve performance. Off-heap memory is not subject to Java
    GC cycles and has a size limit set by the Java property MaxDirectMemorySize.
    The default value is false.

****  maxMemoryOffHeap

    Sets the amount of off-heap memory available to the cache.
    This attribute's values are given as <number>k|K|m|M|g|G|t|T for
    kilobytes (k|K), megabytes (m|M), gigabytes (g|G), or terabytes
    (t|T). For example, maxMemoryOffHeap="2g" allots 2 gigabytes to
    off-heap memory. In effect only if overflowToOffHeap is true.

    The minimum amount that can be allocated is 128MB. There is no maximum.

    Note that it is recommended to set maxElementsInMemory to at least 100 elements
    when using an off-heap store, otherwise performance will be seriously degraded,
    and a warning will be logged.

***  Programmatic Configuration

    The equivalent cache can be created using the following programmatic configuration:

---
public Cache createOffHeapCache() {
  CacheConfiguration config = new CacheConfiguration("sample-offheap-cache", 10000)
    .overflowToOffHeap(true).maxMemoryOffHeap("1G");
  Cache cache = new Cache(config);
  manager.addCache(cache);
  return cache;
}
---

**   Add The License

    The Ehcache Enterprise trial download (available here - {{www.terracotta.org/bigmemory}}) comes with a trial license key
    which must be added to activate the off-heap store.

    It can be added to the classpath or via a system property.

*** Configuring the License in the Classpath

    Add the <<<terracotta-license.key>>> to the root of your classpath, which is also where you add ehcache.xml. It will be
    automatically found.

***  Configuring the License as a Java system property

    Add a <<<org.terracotta.license.path=/path/to/key>>> system property which points to the key location.

    e.g.

---
     java -Dorg.terracotta.license.path=/path/to/key
---


**  Allocating Direct Memory in the JVM

    In order to use these configurations you must then use the ehcache-core-ee jar on your classpath, and modify your JVM command-line
    to increase the amount of direct memory allowed by the JVM.

    e.g. to allocate 2GB of memory in the JVM.

---
    java -XX:MaxDirectMemorySize=2G ..."
---

*  Advanced Configuration Options

    There are some rarer configuration options which can be used for fine grained control

**   -XX:+UseLargePages

    This is a JVM flag which is meant to improve performance of memory-hungry applications.
    In testing, this option gives a 5% speed improvement with a 1Gb off-heap cache.

**  Increasing the maximum serialized size of an Element that can be stored in the OffHeapStore

    Firstly, the MemoryStore and the DiskStore do not have any limits.

    By default, the OffHeapStore has a 4MB limit for classes with high quality hashcodes, and
    256KB for those with pathologically bad hashcodes. The built-in classes such as the
    <<<java.lang.Number>>> subclasses such as Long, Integer etc and and <<<String>>> have
    high quality hashcodes.

    You can increase the size by setting a system property cache_name.maxOffHeapValueSize to
    the size you require.

    e.g. com.company.domain.State.maxOffHeapValueSize=30MB


**  Avoiding OS Swapping

    Operating systems use swap partitions for virtual memory and are free to move less frequently used pages of memory to
    the swap partition. This is generally not what you want when using the OffHeapStore, as the time it takes to swap a page
    back in when demanded will add to cache latency.

    It is recommended that you minimise swap use for maximum performance.

    On Linux, you can set <<</proc/sys/vm/swappiness>>> to reduce the risk of memory pages being swapped out. See {{http://lwn.net/Articles/83588/}}
    for details of tuning this parameter. Note that there are bugs in this which were fixed in kernel 2.6.30 and higher.

    Another option is to configure HugePages. See {{http://unixfoo.blogspot.com/2007/10/hugepages.html}}


    This kind of problem bit us several times in the past in Linux. Although there's a swappiness kernel parameter that can be set to zero, it is usually not enough to avoid swapping altogether. The only surefire way to avoid any kind of swapping is either (a) disabling the swap partition, with the undesirable consequences which that may bring, or (b) using HugePages, which are always mapped to physical memory and cannot be swapped out to disk.

**  Controlling Overallocation of Memory to the OffHeapStore

    If the memory use is dramatically overallocated, you may end up trying to use more than the physical and even virtual memory
    available on your OS. We attempt to detect this situation. If it takes more than 3 seconds to allocate a 1GB chunk of memory
    we will log an error message and call <<<System.exit(1)>>> to protect the stability of your OS.

    If you wish to force Ehcache to wait set the system property <<<net.sf.ehcache.offheap.DoNotHaltOnCriticalAllocationDelay>>> to <<<true>>>.

*   Sample application

    The easiest way to get started is to play with a simple sample app.

    Download {{{/ehcache-offheap-sample.zip}here}} a simple Maven-based application that uses the ehcache off-heap functionality.

    Note: You will need to get a {{{http://www.terracotta.org/bigmemory?src=ehcache.org}license key}} and install it as
    discussed above to run this.


*   Performance Comparisons

    Checkout {{https://svn.terracotta.org/repo/forge/offHeap-test/}} terracotta_community_login a Maven-based performance comparisons between different store
    configurations.

    Note: You will need to get a demo {{{http://www.terracotta.org/bigmemory?src=ehcache.org}license key}} and install it as discussed
    above to run the test.

    Here are some charts from tests we have run on a pre-release alpha version of BigMemory.
    The test machine was an AMD Opteron with 2.8Mhz 4 cpu/8 cores and 64GB memory running RHEL5.1
    with Sun JDK 1.6.0_21 in 64 bit mode.

    We used 50 threads doing an even mix of reads and writes with 1KB elements. We used the default
    garbage collection settings.

    The tests all go through a load/warmup phase then start a performance run. You can use the tests in your own environments and extend
    them to cover different read/write ratios, data sizes, -Xmx settings and hot sets. The full suite, which is done with
    <<<run.sh>>> takes 4-5 hours to complete.

    The following charts show the most common caching use case. The read/write ratio is 90% reads and 10% writes. The hot set is that 90%
    of the time <<<cache.get()>>> will access 10% of the key set. This is representative of the the familiar Pareto distribution that is
    very commonly observed.

    There are of course many other caching use cases. Further performance results are covered on the {{{./offheap_store_further_performance_analysis.html}Further Performance Analysis}} page.


**  Largest Full GC

[images/offheap_fullgc.png]


    This chart shows the largest observed full GC duration which occurred during the performance run. Most non-batch applications have maximum response time
    SLAs. As can be seen in the chart, as data sizes grow the full GC gets worse and worse for cache held on heap, whereas off-heap remains
    a low constant.

    The off-heap store will therefore enable applications with maximum response time SLAs to reliably meet those SLAs.


**  Latency


[images/offheap_maxlatency.png]

    This chart shows the maximum observed latency while perfomring either a <<<cache.put()>>> or a <<<cache.get()>>>. It is very similar to the
    Full GC chart because the reason the on-heap latencies blow out is full GCs, where all threads in the test app get frozen.

    Once again the off-heap store can be observed to have a flat, low maximum latency, because any full GCs are tiny, and the cache has excellent
    concurrency properties.


[images/offheap_latency.png]

    This chart shows the off-heap mean latency in microseconds. It can be observed to be flat from 2GB up to 40GB. Further in-house testing shows
    that the it remains flat up to the limits we have tested to which is currently 350GB.

    Lower latencies are observed at smaller data set sizes because we use a <<<maxElementsInMemory>>> setting which approximates to
    200MB of on-heap store. On-heap, excluding GC effects is faster than off-heap because there is no deserialization on gets.
    At lower data sizes there is a higher probability that the small on-heap store will be hit, which is reflected in the lower average
    latencies.


**  Throughput

[images/offheap_tps.png]

    This chart shows the cache operations per second achieved with off-heap. It is the inverse of average latency and shows much the same
    thing. Once the effect of the on-heap store becomes marginal, throughput remains constant, regardless of cache size. Once again we
    have verified this constancy up to 350GB.

    Note that much larger throughputs than those shown in this chart are achievable. Throughput is affected by:

    * the number of threads (more threads -> more throughput)

    * the read/write ratio (reads are slightly faster)

    * data payload per operation (more data implies a lower throughput in tps but similar in bytes)

    * cpu cores available and their speed (our testing shows that the cpu is always the limiting factor with enough threads. In other
      words cache throughput can be increased by adding threads until all cores are utilised and then adding cpu cores - an ideal
      situation where the software can use as much hardware as you can throw at it.)
    

*   Storage

**  Storage Hierarchy

    With the OffHeapStore, Ehcache Enterprise has three stores:

    * MemoryStore - very fast storage of Objects on heap. Limited by the size of heap you can comfortably garbage collect

    * OffHeapStore - fast (one order of magnitude slower than MemoryStore) storage of Serialized objects off heap. Limited
      only by the amount of RAM on your hardware and address space. You need a 64 bit OS to address higher than 2-4GB.

    * DiskStore - speedy storage on disk. It is two orders of magnitude slower than the OffHeapStore but still much faster
      than a database or a distributed cache

    The relationship between speed and size for each store is illustrated below:


[images/tiered_storage.png]


**  Memory Use in each Store

    As a performance optimisation, and because storage gets much cheaper as you drop down through the hierarchy, we write
    each put to as many stores as are configured. So, if all three are configured, the Element gets written to MemoryStore,
    OffHeapStore and DiskStore.

    The result is that each store consumes storage for itself and the other stores higher up the hierarchy. So, if the MemoryStore
    has 1000,000 Elements which consume 2Gb, and the OffHeapStore is configured for 8GB, then 2GB of that will be duplicate
    of what is in the MemoryStore. And the 8GB will also be duplicated on the DiskStore plus the DiskStore will have what
    cannot fit in any of the other stores.

    This needs to be taken into account when configuring the OffHeap and Disk stores.

    It has the great benefit, which pays for the duplication, of not requiring copy on eviction. On eviction from a store,
    an Element can simply be removed. It is already in the next store down.

*   Handling JVM startup and shutdown

    So you can have a huge in-process cache. But this is not a distributed cache, so when you shut down
    you will lose what is in the cache. And when you start up, how long will it take to load the cache?

    In caches up to a GB or two, these issues are not hugely problematic. You can often pre-load the cache
    on start-up before you bring the application online. Provided this only takes a few minutes, there is
    minimal operations impact.

    But when we go to tens of GBs, these startup times are O(n), and what took 2 minutes now takes 20 minutes.

    To solve this problem, we provide a new implementation of Ehcache's DiskStore, available in the enterprise
    version.

    You simply mark the cache <<<diskPersistent=true>>> as you normally would for a disk persistent cache.

    It works as follows:

    * on startup, which is immediate, the cache will get elements from disk and gradually fill the MemoryStore and
      the OffHeapStore.

    * when running elements are written to the OffHeapStore, they are already serialized. We write these to the DiskStore
      asynchronously in a write behind pattern. Tests show they can be written at a rate of 20MB/s on server class machines
      with fast disks. If writes get behind, they will back up and once they reach the <<<diskSpoolBufferSizeMB>>>
      cache puts will be slowed while the DiskStore writer catches up. By default this buffer is 30MB but can be increased
      through configuration.

    * When the Cache is disposed, only a final sync is required to
      shut the DiskStore down. Tests show that

*   Using OffHeapStore with 32 bit JVMs

    On a 32 bit operating system, Java will always start with a 32 bit data model. On 64 bit OSs, it will default to
    64 bit, but can be forced into 32 bit mode with the Java command line option <<<-d32>>>.
    The problem is that this limits the size of the process to 4GB. Because garbage collection problems are generally
    manageable up to this size, there is not much point in using the OffHeapStore, as it will simply be slower.

    If you are suffering GC issues with a 32 bit JVM, then OffHeapStore can help. There are a few points to keep in mind.

    * Everything has to fit in 4GB of addressable space. If you allocate 2GB of heap (with <<<-Xmx2g>>>) then you have
      at most 2GB left for your off-heap caches.

    * Don't expect to be able to use all of the 4GB of addressable space for yourself. The JVM process requires
          some of it for its code and shared libraries plus any extra Operating System overhead.

    * If you allocate a 3GB heap with -Xmx as well as 2047MB of off-heap memory the virtual machine certainly won't
          complain at startup but when it's time to grow the heap you will get an OutOfMemoryError.

    * If you use both -Xms3G and -Xmx3G with 2047MB of off-heap memory the virtual machine will start but then complain
      as soon as the OffHeapStore tries to allocate the off-heap buffers.

    * Some APIs, such as java.util.zip.ZipFile on Sun 1.5 JVMs, may <mmap> files in memory. This will also use
      up process space and may trigger an OutOfMemoryError.

    For these reasons we issue a warning to the log when OffHeapStore is used with 32 bit JVMs.


*   Slow off-heap allocation

    Off-heap allocation time is measured to avoid allocating too large buffers which cannot fit in memory. If it takes
    more than 1.5s to allocate a buffer a warning is issued as it could very well be that the OS has started paging to
    disk. If it takes more than 15s then the JVM is halted (with <<<System.exit()>>>, but different things are tried when the
    Security Manager prevents this) unless the <<<net.sf.ehcache.offheap.DoNotHaltOnCriticalAllocationDelay>>> system
    property is set to true.

    This mechanism was built in because allocating a off-heap buffer too large to fit in RAM can quickly and easily
    deplete critical system resources like RAM and swap space and crash the host operating system. Linux and Mac OS X
    will crash in these circumstances.


*   FAQ

**   The DiskStore  Access stripes configuration no longer has effect. Why?

    This has been reimplemented for Ehcache Enterprise and will get added back into the core in the future.


**  What Eviction Algorithms are supported?

    The pluggable MemoryStore eviction algorithms work as normal. The OffHeapStore and DiskStore use a
    Clock Cache,a standard paging algorithm which is an approximation of LRU.

**  Why do I see performance slow down and speed up in a cyclical pattern when I am filling a cache?

    This is due to repartitioning in the OffHeapStore which is normal. Once the cache is fully filled
    the performance slow downs cease.

**  What is the maximum serialized size of an object when using OffHeapStore?

    Firstly, the MemoryStore and the DiskStore do not have any limits.

    By default, the OffHeapStore has a 4MB limit for classes with high quality hashcodes, and
    256KB for those with pathologically bad hashcodes. The built-in classes such as the
    <<<java.lang.Number>>> subclasses such as Long, Integer etc and and <<<String>>> have
    high quality hashcodes.

    You can increase the size by setting a system property cache_name.maxOffHeapValueSize to
    the size you require.

    e.g. com.company.domain.State.maxOffHeapValueSize=30MB

**  Why is my application startup slower?

    On startup the CacheManager will calculate the amount of off-heap storage required for all caches
    using off-heap stores. The memory will be allocated from the OS and zeroed out by Java. The time taken
    will depend on the OS. A server class machine running Linux will take approximately half a second per GB.

    We print out log messages for each 10% allocated, and also report the total time taken.

    This time is only incurred once at startup. The pre-allocation of memory from the OS is one of the reasons
    that runtime performance is so fast.






