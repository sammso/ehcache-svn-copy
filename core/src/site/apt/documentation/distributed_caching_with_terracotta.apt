{Distributed Caching Using Terracotta}

    Terracotta has been integrated with Ehcache since Ehcache 1.4.

    From version 1.7 Ehcache has been seamlessly integrated with Terracotta 3.1.1 and takes just a few lines
    of config in ehcache.xml to get up and running.

*   Worked Example

    As this example shows, running Ehcache with Terracotta clustering is no different from normal programmatic use.

---
import net.sf.ehcache.Cache;
import net.sf.ehcache.CacheManager;
import net.sf.ehcache.Element;

public class TerracottaExample {
    CacheManager cacheManager = new CacheManager();

    public TerracottaExample() {
        Cache cache = cacheManager.getCache("sampleTerracottaCache");
        int cacheSize = cache.getKeys().size();
        cache.put(new Element("" + cacheSize, cacheSize));
        for (Object key : cache.getKeys()) {
            System.out.println("Key:" + key);
        }
    }

    public static void main(String[] args) throws Exception {
        new TerracottaExample();
    }
}

---

    The above example looks for sampleTerracottaCache.

    In ehcache.xml, we need to uncomment or add the following line:

---
    <terracottaConfig url="localhost:9510"/>
---
    which tells Ehcache to load the Terracotta server config from localhost port 9510. Note: You must have a
    Terracotta 3.1.1 or higher server running locally for this example.

    Next we want to enable Terracotta clustering for the cache named <<<sampleTerracottaCache>>>. Uncomment or add the
    following in ehcache.xml.
    
---
   <cache name="sampleTerracottaCache"
          maxElementsInMemory="1000"
          eternal="false"
          timeToIdleSeconds="3600"
          timeToLiveSeconds="1800"
          overflowToDisk="false">
       <terracotta/>
   </cache>
---

    That's it!


*   Terracotta Configuration

    Terracotta configuration in ehcache.xml is in three parts:

    * CacheManager Configuration

    * Terracotta Server Configuration

    * Enabling Terracotta clustering per cache

**  CacheManager Configuration

    The attributes of <ehcache> are:

    * name

    an optional name for the CacheManager.  The name is optional and primarily used
    for documentation or to distinguish Terracotta clustered cache state.  With Terracotta
    clustered caches, a combination of CacheManager name and cache name uniquely identify a
    particular cache store in the Terracotta clustered memory.

    The name will show up in the Developer Console.s

    * {updateCheck}

    an optional boolean flag specifying whether this CacheManager should check
    for new versions of Ehcache over the Internet.  If not specified, updateCheck="true".

    * monitoring

    an optional setting that determines whether the CacheManager should
    automatically register the SampledCacheMBean with the system MBean server.  Currently,
    this monitoring is only useful when using Terracotta and thus the "autodetect" value
    will detect the presence of Terracotta and register the MBean.  Other allowed values
    are "on" and "off".  The default is "autodetect".

---
<Ehcache xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:noNamespaceSchemaLocation="ehcache.xsd"
             updateCheck="true" monitoring="autodetect">

---

**  {Terracotta Server Configuration}

    Note: You need to install and run one or more Terracotta servers to use Terracotta clustering.

    See http://www.terracotta.org/web/display/orgsite/Download.

    With a server/servers up and running you need to specify the location of the servers.

    Configuration can be specified in two main ways: by reference to a source of
    configuration or by use of an embedded Terracotta configuration file.

*** Specification of a source of configuration

    To specify a reference to a source (or sources) of configuration, use the url
    attribute.  The url attribute must contain a comma-separated list of:

    * path to the Terracotta configuration file (usually named tc-config.xml)

    Example using a path to Terracotta configuration file:

---
    <terracottaConfig url="/app/config/tc-config.xml"/>
---

    * URL to the Terracotta configuration file

    Example using a URL to a Terracotta configuration file:

---
    <terracottaConfig url="http://internal/ehcache/app/tc-config.xml"/>
---

    * <server host>:<port> of a running Terracotta Server instance

    Example pointing to a Terracotta server installed on localhost:

---
    <terracottaConfig url="localhost:9510"/>
---

    Example using multiple Terracotta server instance URLs (for fault tolerance):

---
    <terracottaConfig url="host1:9510,host2:9510,host3:9510"/>
---

*** Specification using embedded tc-config

    To embed a Terracotta configuration file within the Ehcache configuration, simply
    place the usual Terracotta XML config within the <terracottaConfig> element.

    In this example we have two Terracotta servers running on <<<server1>>> and <<<server2>>>.
    
---
    <terracottaConfig>
        <tc-config>
            <servers>
                <server host="server1" name="s1"/>
                <server host="server2" name="s2"/>
            </servers>
            <clients>
                <logs>app/logs-%i</logs>
            </clients>
        </tc-config>
    </terracottaConfig>
---


** Enabling Terracotta clustering per cache

    Cache elements can also contain information about whether the cache can be clustered with Terracotta.

    The <terracotta> sub-element has the following attributes:

    * <<<clustered=true|false>>>

      Indicates whether this cache should be clustered with Terracotta. By
      default, if the <terracotta> element is included, clustered=true.

    * <<<valueMode=serialization|identity>>>

      Indicates whether this cache should be clustered with
      serialized copies of the values or using Terracotta identity mode.  By default, values will
      be cached in serialization mode which is similar to other replicated Ehcache modes.  The identity
      mode is only available in certain Terracotta deployment scenarios and will maintain actual object
      identity of the keys and values across the cluster.  In this case, all users of a value retrieved from
      the cache are using the same clustered value and must provide appropriate locking for any changes
      made to the value (or objects referred to by the value).

    * <<<coherentReads=true|false>>>

      Indicates whether this cache should have coherent reads with guaranteed consistency across the cluster.
       By default, this setting is true.  If you set this property to
      false, reads are allowed to check the local value without locking, possibly seeing stale values.

      This is a performance optimization with weaker concurrency guarantees and should generally be used
      with caches that contain read-only data or where the application can tolerate reading stale
      data.

    The simplest way to enable clustering is to add:

---
        <terracotta/>
---

    To indicate the cache should not be clustered (or remove the <terracotta> element altogether):

---
        <terracotta clustered="false"/>
---

    To indicate the cache should be clustered using identity mode:

---
        <terracotta clustered="true" valueMode="identity"/>
---

    Following is an example Terracotta clustered cache named sampleTerracottaCache.

---
    <cache name="sampleTerracottaCache"
           maxElementsInMemory="1000"
           eternal="false"
           timeToIdleSeconds="3600"
           timeToLiveSeconds="1800"
           overflowToDisk="false">
        <terracotta/>
    </cache>
---

*   Behaviour differences with <<<CacheEventListener>>>s when using Terracotta Clustering

    Terracotta clustering works by clustering the <<<MemoryStore>>>, unlike the replication mechanisms which use the
    <<<CacheEventListener>>> infrastructure.

    This results in a simpler programming contract than with the replication mechanisms.

    Things to note:

**  Cache listeners

    Cache listeners listen for changes, including replicated cluster changes, made through the Cache API. Because
    Terracotta cluster changes happen transparently directly to the <<<MemoryStore>>> a listener will not be invoked
    when an event occurs out on the cluster. If it occurs locally, then it must have occurred through the Cache API, so
    a local event will be detected by a local listener.

    A common use of listeners is to trigger a reload of a just invalidated <<<Element>>>. In Terracotta clustering
    this is avoided as a change in one node is always coherent to the other nodes.

**  Overflow to Disk

    Overflow to Disk is not supported when using Terracotta Clustering. However it is also not needed, because the
    Terracotta server has its own overflow to disk. Once the <<<maxElementsInMemory>>> limit is reached <<<Element>>>s will be
    evicted to the cluster.

*   More Information

    Please see {{{http://www.terracotta.org/web/display/orgsite/Terracotta+Ehcache+Overview}Terracotta Documentation}}
    for much more information.


    
*  FAQ


**  Is Expiry the same in Terracotta?

    timeToIdle and timeToLive work as usual. Ehcache 1.7 introduced a less fine grained age recording in Element
    which rounds up to the nearest second. Some APIs may be sensitive to this change.

    In Ehcache Elements can have overridden TTI and TTLs. Terracotta supports this functionality.

**  What Eviction strategies are supported?

    Ehcache supports LRU, LFU and FIFO eviction strategies.

    Terracotta supports LRU and LFU eviction from the local node. Not FIFO and not custom evictors.

**  What Stores are available and how are they configured?

    The Terracotta server provides an additional store, generally referred to as the Level 2 or {L2} store.

    The MemoryStore in JVM in the local node is referred to as the {L1} Store.

    maxElementsInMemory - the maximum number of elements in the local L1 store.

    maxElementsOnDisk - is overridden when using Terracotta to provide the L2 size.

    overflowToDisk normally controls whether to overflow to the DiskStore. This is ignored when using Terracotta - the DiskStore
    is never used. When the store gets full, elements will always overflow to the Terracotta L2 Store running on the server. The L2
    can be further configured with the tcconfig.

**  When do Elements overflow?

    Two things to cause elements to be flushed from L1 to L2.

    * the L1 store exceeding maxElementsInMemory

    * When the local JMV exceeds 70% of Old Generation. This can be turned off in the TC Config. By default it is on (in 1.7).

**  How does Element equality work in Serialization mode?

    An Element in Ehcache is guaranteed to <<<.equals()>>> another as it moves between stores.

    In the Express install or Serialization mode of Terracotta, which is the default, Terracotta is the same. Elements will
    not <<<==>>> each other as they move between stores.

**  How does Element equality work in Identity mode?

    An Element in Ehcache is guaranteed to <<<.equals()>>> another as it moves between stores.

    However in Identity mode, Terracotta makes a further guarantee - that they will <<<==>>> each other. This is achieved
    using extensions to the Java Memory Model.

**  What is the recommended way to write to a database?

    Terracotta' non Ehcache API offers an async writethrough to the database which is guaranteed. It uses the TIM Async module and works
    by putting the database update in a clustered queue. It guarantees that a node, even if the local node fails, will take it out
    and process it.

    That option is not available with Ehcache although it may get added.

**  If updates to a database bypass the Terracotta clustered application, then how is that coherent?

    It isn't. This is a problem with using a database as an integration point. Integration via a message queue, with a
    Terracotta clustered application acting as a message queue listener and updating the database avoids this. As would
    The application receiving a REST or SOAP call and writing to the database.

    AQ can have DB trigger put in a poll. Or AQ can push it up.


**  Do CacheEventListeners work?

    A local CacheEventListener will work locally, but other nodes in a Terracotta cluster are not notified. With the Ehcache replication
     non Terracotta mechanisms the remote nodes are updated.  







    
