 ---
 {Search}
 ---

Search

%{toc|fromDepth=2|toDepth=2}

* Ehcache Search API

    _new_ The Ehcache Search API allows you to execute arbitrarily complex queries against either a standalone cache or a Terracotta
    clustered cache with pre-built indexes. Searchable attributes may be extracted from both keys and values. Keys, values,
     or summary values (Aggregators) can all be returned.


    Here is a simple example: Search for 32 year old males and return the cache keys.

---
Results results = cache.createQuery().includeKeys().add(and(age.eq(32),
    gender.eq("male"))).execute();
---

    Note: This feature is in pre-release and will be released with ehcache-core 2.4.0. Maven builds for version 2.4.0-SNAPSHOT are published to
    {{{http://oss.sonatype.org/content/repositories/sourceforge-snapshots/net/sf/ehcache/}oss.sonatype.org}} and are available there if you
    would like to try out the standalone implementation.

*  What is searchable?

    Searches can be performed against Element keys, values and metadata, such as creation time.
     
    Element keys and values are made searchable by extracting attributes with supported search types out of the values.

    It is the attributes themelves which are searchable.

*   How to make a cache searchable

**  By Configuration

    Caches are made searchable by adding a \<searchable/\> tag to the ehcachel.xml.

---
<cache name="cache2" maxElementsInMemory="10000" eternal="true" overflowToDisk="false">
    <searchable/>
</cache>
---

    This configuration will scan keys and vales and if they are of supported search types, add them as
    attributes called "key" and "value" respectively.

    Ehcache element metadata can be also searched if it is declared searchable. This is done as follows:

---
<cache name="metadata-searchable" maxElementsInMemory="0" eternal="true" overflowToDisk="false">
   <searchable metadata="true"/>
</cache>
---

    Lots of times keys or values will not be directly searchable and instead you will need to extract searchable attributes out of them.
    The following example shows this more typical case.  Attribute Extractors are explained in more detail in the following section.

---
<cache name="cache3" maxElementsInMemory="10000" eternal="true" overflowToDisk="false">
    <searchable>
        <searchAttribute name="age" class="net.sf.ehcache.search.TestAttributeExtractor"/>
        <searchAttribute name="gender" expression="value.getGender()"/>
    </searchable>
</cache>
---

**  Programmatically

    You can create new <<<SearchAttribute>>>s and add them to your cache configuration, and then create your cache.

    This example shows how:

---
CacheConfiguration cacheConfig = new CacheConfiguration("test", -1).eternal(true);

// Create attributes on the stuff we want to be able to search on.
// You can use an expression for getting at the value to be indexed on a cache or you can
// code your own.

// Expression
SearchAttribute sa = new SearchAttribute();
sa.setExpression("value.getAge()");
sa.setName("age");
cacheConfig.addSearchAttribute(sa);

// Coding your own
sa = new SearchAttribute();
sa.className("org.sharrissf.sample.EhcacheSearchPlaying$NameAttributeExtractor");
sa.setName("name");
cacheConfig.addSearchAttribute(sa);

sa = new SearchAttribute();
sa.setExpression("value.getGender()");
sa.setName("gender");
cacheConfig.addSearchAttribute(sa);

sa = new SearchAttribute();
sa.setExpression("value.getAddress().getState()");
sa.setName("state");
cacheConfig.addSearchAttribute(sa);

Cache test = new Cache(cacheConfig);
cacheManager.add(test);
---


*  Attribute Extractors
  
    Attributes are extracted from keys or values. This is done on <<<put()>>> into the cache
    using <<<AttributeExtractor>>>s in the clustered implementation and during search in the standalone implementation 

    Extracted attributes must be one of the following supported types:
    
        *   Boolean
        
        *   Byte
        
        *   Character
        
        *   Double
        
        *   Float
        
        *   Integer
        
        *   Long
        
        *   Short 
        
        *   String
        
        *   Date

        *   Enum
        
    If an attribute cannot be extracted due to not being found or of being the wrong type an AttributeExtractorException is thrown
    during the <<<put()>>> in the clustered implementation and on search execution in the standalone implementation


**  Well-known Attributes

    The parts of an Element are well-known attributes that can be referenced by some predefined, well-known names.

    If a keys and/or value is of a supported search type, they are added automatically as attributes with the names
    "key" amd "value".

    When the metadata attribute is set (<<<metadata=true>>>), the following metadata attibutes are also indexed and made available:

     * creationTime

     * expirationTime

     * lastAccessTime

     * lastUpdateTime

     * version

    All of these well-known attributes have convenience constant attributes made available on the <<<Query>>> class.
    So, for example, the attribute for "key" may be referenced in a query by <<<Query.KEY>>>. For even greater readability it is
     recommended to statically import so that in this example you would just use <<<KEY>>>.

*----------+--------------+
Well-known Attribute Name | Attribute Constant
*----------+--------------+
 key               |     Query.KEY
*----------+--------------+
 value             |     Query.VALUE
*----------+--------------+
 creationTime      |     Query.CREATION_TIME
*----------+--------------+
 expirationTime    |    Query.EXPIRATION_TIME
*----------+--------------+
 lastAccessTime    |   Query.LAST_ACCESS_TIME
*----------+--------------+
 lastUpdateTime    |   Query.LAST_UPDATE_TIME
*----------+--------------+
 version           |   Query.VERSION
*----------+--------------+


** ReflectionAttributeExtractor

    The ReflectionAttributeExtractor is a built-in search attribute extractor which uses JavaBean conventions and also understands
    a simple form of expression.

    Where a JavaBean property is available and it is of a searchable type, it can be simply declared using:

---
<cache>
    <searchable>
        <searchAttribute name="age"/>
    </searchable>
</cache>
---

  Finally, when things get more complicated, we have an expression language using method/value dotted expression chains.

  The expression chain must start with one of either "key", "value", or "element". From the starting object
  a chain of either method calls or field names follows. Method calls and field names can be freely mixed in the chain.

  Some more examples:

---
<cache>
    <searchable>
        <searchAttribute name="age" expression="value.person.getAge()"/>
    </searchable>
</cache>
---

---
<cache>
    <searchable>
        <searchAttribute name="name" expression="element.toString()"/>
    </searchable>
</cache>
---

  The method and field name portions of the expression are case sensitive.

** Custom AttributeExtractor

  In more complex situations you can create your own attribute extractor by implementing the AttributeExtractor interface. Providing your 
  extractor class is shown in the following example:
    
---  
<cache name="cache2" maxElementsInMemory="0" eternal="true" overflowToDisk="false">
    <searchable>
        <searchAttribute name="age" class="net.sf.ehcache.search.TestAttributeExtractor"/>
    </searchable>
</cache>
---  
  
*  Search Query Language

    Ehcache Search introduces an Object Oriented query language, following DSL principles, which should feel familiar and natural to Java programmers.

    Here is a simple example:

---
Query query = cache.createQuery().add(age.eq(35)).includeKeys().end();
Results results = query.execute();
---

**  Using attributes in queries

  If declared and available, the well-known attributes are referenced by their name or the convenience attributes are used
   directly as shown in this example:

---
Results results = cache.createQuery().add(Query.KEY.eq(35)).execute();
Results results = cache.createQuery().add(Query.VALUE.lt(10)).execute();
Results results = cache.createQuery().add(Query.VERSION.ge(2)).execute();
---

    Other attributes are referenced by the names given them in the configuration. E.g.

---
Attribute<Integer> age = cache.getSearchAttribute("age");
Attribute<String> gender = cache.getSearchAttribute("gender");
Attribute<String> name = cache.getSearchAttribute("name");
---

** Expressions

    The Query to be searched for is built up using Expressions.

    Expressions include logical operators such as <and> and <or>. It also includes comparison operators such as <ge> (>=), <between> and <like>

    <<<add(...)>>> is used to add a clause to a query. Adding a further clause automatically <and>s the clauses

---
query = cache.createQuery().includeKeys().add(age.le(65)).add(gender.eq("male")).end();
---

    Both logical and comparison operators implement the <<<Criteria>>> interface.

    To add a criteria with a different logical operator, you need to explicitly nest it within a new logical operator Criteria Object.

    e.g. to check for age = 35 or gender = female, do the following:

---
query.add(new Or(age.eq(35),
                 gender.eq(Gender.FEMALE))
         );
---

    More complex compound expressions can be further created with extra nesting.

    See the {{{http://ehcache.org/xref/net/sf/ehcache/search/expression/package-frame.html}Expression JavaDoc}} for a complete list.

** Making queries immutable

  By defualt a query can be executed and then modified and re-executed. If <<<end>>> is called
  the query is made immutable.

** Automatically Deleting Elements which match a Query

    <<<executeRemove>>> may be used in place of excecute to automatically remove Elements which match the Query. The return type
    and syntax is identical. The <<<Results>>> object returned then contains what was removed from the Cache. If all you want
    to know is the count of Elements removed, you would use the count aggregator as per the following example:

---
Results results = query.includeAggregator(KEY.count()).executeRemove();
---

    While it is possible to simply return the keys from a Query and then iterate over them yourself, executeRemove has been
    optimised for more efficient operation in each implementation.

**  Ordering Results

    Query results may be ordered in ascending or descending order by adding an <<<addOrder>>> clause to the query, which takes
    as parameters the attribute to order by and the ordering direction.

    e.g. to order the results by ages in ascending order
---
query.addOrder(age, Direction.ASCENDING);
---


**   Limiting the size of Results

    By default a query will return an unlimited number of results. For example the following
    query will return all keys in the cache.

---
Query query = cache.createQuery();
query.includeKeys();
query.execute();
---

    If too many results are returned it could cause an OutOfMemoryError

    The <<<maxResults>>> clause is used to limit the size of the results.

    e.g. to limit the above query to the first 100 elements found:

---
Query query = cache.createQuery();
query.includeKeys();
query.maxResults(100);
query.execute();
---

    If a returns a very large result, you can get it in chunks with <<<Results.range()>>>.

* Search Results

  Queries return a <<<Results>>> object which contains a list of objects of class <<<Result>>> plus
   any <<<Aggregator>>> results.

**  Results

  Either all results can be returned using <<<results.all()>>> to get the all in one chunk, or a range of results
  using <<<results.range(int start, int count)>>> to achieve paging.

  When you are done with the results, it is recommended to call <<<discard()>>>. This allows resources to be freed.
  In the distributed implementation with Terracotta, resources may be used to hold results for paging or return.

  To determine what was returned by the query use one of the interrogation methods on <<<Results>>>:

  * <<<hasKeys()>>>

  * <<<hasAttributes()>>>

  * <<<hasAggregators()>>>

  Aggregator results are summaries computed for the search. They are available <<<Results.getAggregatorResults>>> which returns
   a list of <<<Aggregator>>>s in the same order in which they were used in the <<<Query>>>.

** Result

   Each <<<Element>>> in the cache found with a query will be represented as a <<<Result>>> object. So if a query finds
   350 elements there will be 350 <<<Result>>> objects.

   A Result object can contain either:

   *    the Element key - when <<<includeKeys()>>> was added to the query

   *    predefined attribute(s) extracted from an Element value - when <<<includeAttribute(...)>>> was added to the query. To access
        an attribute from Result, use <<<getAttribute(Attribute<T> attribute>>>.

**  Aggregators

    Aggregators are added with <<<query.includeAggregator(\<attribute\>.\<aggregator\>)>>>.

    E.g. to find the sum of the age attribute:

---
query.includeAggregator(age.sum());
---

    See the {{{http://ehcache.org/xref/net/sf/ehcache/search/aggregator/package-frame.html}Aggregators JavaDoc}} for a complete list.


*   Sample Application

    We have created a simple standalone sample application with few dependencies for you to easily get started with Ehcache Search.

    {{{http://github.com/downloads/sharrissf/Ehcache-Search-Sample/ehcache-search-sample-0.0.1-SNAPSHOT-distribution.tar.gz}Download}} it
    or check out the source:

---
git clone git://github.com/sharrissf/Ehcache-Search-Sample.git
---

    The {{{http://ehcache.org/xref-test/net/sf/ehcache/search/package-summary.html}Ehcache Test Sources}} show lots of further examples
    on how to use each Ehcache Search feature.

*   Scripting Environments

    Ehcache Search is readily amenable to scripting. The following example shows how to use it with BeanShell:

---
Interpreter i = new Interpreter();

//Auto discover the search attributes and add them to the interpreter's context
Map<String, SearchAttribute> attributes = cache.getCacheConfiguration().getSearchAttributes();
for (Map.Entry<String, SearchAttribute> entry : attributes.entrySet()) {
    i.set(entry.getKey(), cache.getSearchAttribute(entry.getKey()));
    LOG.info("Setting attribute " + entry.getKey());
}

//Define the query and results. Add things which would be set in the GUI i.e.
//includeKeys and add to context
Query query = cache.createQuery().includeKeys();
Results results = null;
i.set("query", query);
i.set("results", results);

//This comes from the freeform text field
String userDefinedQuery = "age.eq(35)";

//Add the stuff on that we need
String fullQueryString = "results = query.add(" + userDefinedQuery + ").execute()";

i.eval(fullQueryString);
results = (Results) i.get("results");
assertTrue(2 == results.size());
for (Result result : results.all()) {
    LOG.info("" + result.getKey());
}
---

*   Concurrency Considerations

    Unlike cache operations which has selectable concurrency control and/or transactions, the Search API does not. This may change
    in a future release, however our survey of prospective users showed that concurrency control in search indexes was not sought after.

    The indexes are eventually consistent with the caches.

**  Index updating

    Indexes will be updated asynchronously, so there state will lag slightly behind the state of the cache. The only exception is when
    the updating thread then performs a search.

    For caches with concurrency control, an index will not reflect the new state of the cache until:

    * The change has been applied to the cluster.

    * For a cache with transactions, when <<<commit>>> has been called.

**  Query Results

    There are several ways unexpected results could present:

    *   A search returns an Element reference which no longer exists.

    *   Search criteria select an Element, but the Element has been updated and a new Search would no longer match the Element.

    *   Aggregators, such as sum(), might disagree with the same calculation done by redoing the calculation yourself by re-accessing the
        cache for each key and repeating the calculation.

**  Recommendations

    Because the state of the cache can change between search executions it is recommended to add all of the Aggregators you want
    for a query at once so that the returned aggregators are consistent.

    Use null guards when accessing a cache with a key returned from a search.

*   Implementations

**  Standalone Ehcache

    The standalone Ehcache implementation does not use indexes. It uses fast iteration of the cache
    instead, relying on the very fast access to essentially do the equivalent of a table scan for each
    query.

    Attributes are not extracted ahead of time. They are done during query execution.

*** Performance

    Search operations perform in O(n) time.

    Accordingly, this implementation is suitable for development and testing. For production it is recommended to only
    search against caches that are less than 100,000 element in size.

    An indexed implementation may be done in future.

**  Ehcache backed by the Terracotta Server Array

    This implementation uses Lucene indexes which are maintained on each Terracotta server. In Ehcache EX the index is
    on a single active server. In Ehcache FX the cache is sharded across the number of active nodes in the cluster. The index
    for each shard is maintained on that shard's server.

    Searches are performed using the Scatter-Gather pattern. The query executes on each node and the results are then aggregated
    back in the Ehcache that initiated the search.

*** Performance

    Search operations perform in O(log n / number of shards) time.

    Performance is excellent and can be improved simply by adding more servers to the FX array.

*** Network Effects

    Search results are returned over the network. The data returned could potentially be very large, so
    techniques to limit return size are recommended such as:

    * limiting the results with <<<maxResults>>> or using the paging API <<<Results.range(int start, int length)>>>

    * Returning keys instead of values using <<<includeKeys()>>> in the query

    * Returning attributes instead of values

    * using a built-in <<<Aggregator>>> function when you only need a summary statistic


*   Limitations in the alpha release

    The above documentation is written for how we see search working when it is released.

    * The alpha API may be changed before final release

    * Performance optimisations for standalone have not been done

    * executeRemove() is not yet implemented

    * Metadata attributes are not yet implemented 


*   Not planned for First Release

    * Add Query.includeValues() that is orthogonal to includeKeys() and can be more efficient network wise for round trips where values are required

    * indexed standalone implementation

    * User Defined Aggregators

