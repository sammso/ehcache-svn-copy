 ---
 Off-heap Store
 ---

{Off-heap Store}

    Terracotta BigMemory add-on to Enterprise Ehcache permits caches to use a memory store that is outside the object heap and is 100 times faster than the DiskStore.
    
    This off-heap store, which is not subject to Java GC, allows very large caches to be created (we have tested up to 256GB).
    
    Because off-heap data is stored in bytes, there are two
    implications:

    * Only Serializable cache keys and values can be placed in the store, similar to DiskStore.

    * Serialization and deserialization take place on putting and getting from the store. While this may make the off-heap store seem slower (in theory
      10 times slower than the MemoryStore), overall performance makes substantial gains bypassing the latency of hard-disk access and the pauses of Java GC.


*   Configuration

**  Configuring caches to overflow to off-heap.

    Configuring a cache to use an off-heap store can be done either through XML or programmatically.

***  Declarative Configuration

    The following XML configuration creates an offheap-cache with a in-heap store (maxElementsInMemory) of 10,000 elements which
    overflow to a 1-gigabyte off-heap area.

---
    <?xml version="1.0" encoding="UTF-8"?>
    <ehcache updateCheck="false" monitoring="off"
             dynamicConfig="false">

        <defaultCache maxElementsInMemory="10000"
                      eternal="true"
                      memoryStoreEvictionPolicy="LRU"
                      statistics="false" />

        <cache name="sample-offheap-cache"
               maxElementsInMemory="10000"
               eternal="true"
               memoryStoreEvictionPolicy="LRU"
               overflowToOffHeap="true"
               maxMemoryOffHeap="1G"/>
    </ehcache>
---

***  Programmatic Configuration

    The equivalent cache can be created using the following programmatic configuration:

---
    public Cache createOffHeapCache() {
      CacheConfiguration config = new CacheConfiguration("sample-offheap-cache", 10000).overflowToOffHeap(true).maxMemoryOffHeap("1G");
      Cache cache = new Cache(config);
      manager.addCache(cache);
      return cache;
    }
---

**   Add The License

    The Ehcache Enterprise download kit (available here - please add URL) contains a trial license key which must be added to activate
    the off-heap store.

    It can be added in two ways:

***  In the classpath

    Add the <<<terracotta-license.key>>> to the root of your classpath, which is also where you add ehcache.xml. It will be
    automatically found.

***  Specify the key in a Java system property

    Add a <<<org.terracotta.license.path=/path/to/key>>> system property which points to the key location.

    e.g.

---
     java -Dorg.terracotta.license.path=/path/to/key
---


**  Allocating Direct Memory in the JVM

    In order to use these configurations you must then use the ehcache-core-ee jar on your classpath, and modify your JVM command-line
    to increase the amount of direct memory allowed by the JVM.

    e.g. to allocate 2GB of memory in the JVM.

---
    java -XX:MaxDirectMemorySize=2G -cp "ehcache-core-ee-2.3.0.jar:slf4j-api-1.5.11.jar:slf4j-jdk14-1.5.11.jar"
---


*  Advanced Configuration Options

    There are some rarer configuration options which can be used for fine grained control

**   -XX:+UseLargePages

    This is a JVM flag which is meant to improve performance of memory-hungry applications.
    In testing, this option gives a 5% speed improvement with a 1Gb off-heap cache.

**  Increasing the maximum serialized size of an Element that can be stored in the OffHeapStore

    Firstly, the MemoryStore and the DiskStore do not have any limits.

    By default, the OffHeapStore has a 4MB limit for classes with high quality hashcodes, and
    256KB for those with pathologically bad hashcodes. The built-in classes such as the
    <<<java.lang.Number>>> subclasses such as Long, Integer etc and and <<<String>>> have
    high quality hashcodes.

    You can increase the size by setting a system property cache_name.maxOffHeapValueSize to
    the size you require.

    e.g. com.company.domain.State.maxOffHeapValueSize=30MB


**  Avoiding OS Swapping

    Operating systems use swap partitions for virtual memory and are free to move less frequently used pages of memory to
    the swap partition. This is generally not what you want when using the OffHeapStore, as the time it takes to swap a page
    back in when demanded will add to cache latency.

    It is recommended that you minimise swap use for maximum performance.

    On Linux, you can set <<</proc/sys/vm/swappiness>>> to reduce the risk of memory pages being swapped out. See {{http://lwn.net/Articles/83588/}}
    for details of tuning this parameter. Note that there are bugs in this which were fixed in kernel 2.6.30 and higher.

    Another option is to configure HugePages. See {{http://unixfoo.blogspot.com/2007/10/hugepages.html}}
    

    This kind of problem bit us several times in the past in Linux. Although there's a swappiness kernel parameter that can be set to zero, it is usually not enough to avoid swapping altogether. The only surefire way to avoid any kind of swapping is either (a) disabling the swap partition, with the undesirable consequences which that may bring, or (b) using HugePages, which are always mapped to physical memory and cannot be swapped out to disk.

**  Controlling Overallocation of Memory to the OffHeapStore

    If the memory use is dramatically overallocated, you may end up trying to use more than the physical and even virtual memory
    available on your OS. We attempt to detect this situation. If it takes more than 3 seconds to allocate a 1GB chunk of memory
    we will log an error message and call <<<System.exit(1)>>> to protect the stability of your OS.

    

In case this detection is bogus on some JVM / OS combination I added a net.sf.ehcache.offheap.DoNotHaltOnCriticalAllocationDelay system property that when set to true, prevents the VM halt code from being executed and only warnings are logged then.




*   Sample application

    Download here a simple Maven-based application that uses the ehcache off-heap functionality.

    Note: You will need to get a license key as discussed above to run this.


*   Storage Hierarchy

    With the OffHeapStore, Ehcache Enterprise has three stores:

    * MemoryStore - very fast storage of Objects on heap. Limited by the size of heap you can comfortably garbage collect

    * OffHeapStore - fast (one order of magnitude slower than MemoryStore) storage of Serialized objects off heap. Limited
      only by the amount of RAM on your hardware and address space. You need a 64 bit OS to address higher than 2-4GB.

    * DiskStore - speedy storage on disk. It is two orders of magnitude slower than the OffHeapStore but still much faster
      than a database or a distributed cache


**  Storage Consumption

    As a performance optimisation, and because storage gets much cheaper as you drop down through the hierarchy, we write
    each put to as many stores as are configured. So, if all three are configured, the Element gets written to MemoryStore,
    OffHeapStore and DiskStore.

    The result is that each store consumes storage for itself and the other stores higher up the hierarchy. So, if the MemoryStore
    has 1000,000 Elements which consume 2Gb, and the OffHeapStore is configured for 8GB, then 2GB of that will be duplicate
    of what is in the MemoryStore. And the 8GB will also be duplicated on the DiskStore plus the DiskStore will have what
    cannot fit in any of the other stores.

    This needs to be taken into account when configuring the OffHeap and Disk stores.

    It has the great benefit, which pays for the duplication, of not requiring copy on eviction. On eviction from a store,
    an Element can simply be removed. It is already in the next store down.

*   Handling JVM startup and shutdown

    So you can have a huge in-process cache. But this is not a distributed cache, so when you shut down
    you will lose what is in the cache. And when you start up, how long will it take to load the cache?

    In caches up to a GB or two, these issues are not hugely problematic. You can often pre-load the cache
    on start-up before you bring the application online. Provided this only takes a few minutes, there is
    minimal operations impact.

    But when we go to tens of GBs, these startup times are O(n), and what took 2 minutes now takes 20 minutes.

    To solve this problem, we provide a new implementation of Ehcache's DiskStore, available in the enterprise
    version.

    You simply mark the cache <<<diskPersistent=true>>> as you normally would for a disk persistent cache.

    It works as follows:

    * on startup, which is immediate, the cache will get elements from disk and gradually fill the MemoryStore and
      the OffHeapStore.

    * when running elements are written to the OffHeapStore, they are already serialized. We write these to the DiskStore
      asynchronously in a write behind pattern. Tests show they can be written at a rate of 20MB/s on server class machines
      with fast disks. If writes get behind, they will back up and once they reach the <<<diskSpoolBufferSizeMB>>>
      cache puts will be slowed while the DiskStore writer catches up. By default this buffer is 30MB but can be increased
      through configuration.

    * When the Cache is disposed, only a final sync is required to
      shut the DiskStore down. Tests show that

*   Using OffHeapStore with 32 bit JVMs
    
    On a 32 bit operating system, Java will always start with a 32 bit data model. On 64 bit OSs, it will default to
    64 bit, but can be forced into 32 bit mode with the Java command line option <<<-d32>>>.
    The problem is that this limits the size of the process to 4GB. Because garbage collection problems are generally
    manageable up to this size, there is not much point in using the OffHeapStore, as it will simply be slower.

    If you are suffering GC issues with a 32 bit JVM, then OffHeapStore can help. There are a few points to keep in mind.

    * Everything has to fit in 4GB of addressable space. If you allocate 2GB of heap (with <<<-Xmx2g>>>) then you have
      at most 2GB left for your off-heap caches.

    * Don't expect to be able to use all of the 4GB of addressable space for yourself. The JVM process requires
          some of it for its code and shared libraries plus any extra Operating System overhead.

    * If you allocate a 3GB heap with -Xmx as well as 2047MB of off-heap memory the virtual machine certainly won't
          complain at startup but when it's time to grow the heap you will get an OutOfMemoryError.

    * If you use both -Xms3G and -Xmx3G with 2047MB of off-heap memory the virtual machine will start but then complain
      as soon as the OffHeapStore tries to allocate the off-heap buffers.

    * Some APIs, such as java.util.zip.ZipFile on Sun 1.5 JVMs, may <mmap> files in memory. This will also use
      up process space and may trigger an OutOfMemoryError.

    For these reasons we issue a warning to the log when OffHeapStore is used with 32 bit JVMs.


*   Slow off-heap allocation

    Off-heap allocation time is measured to avoid allocating too large buffers which cannot fit in memory. If it takes
    more than 1.5s to allocate a buffer a warning is issued as it could very well be that the OS has started paging to
    disk. If it takes more than 15s then the JVM is halted (with <<<System.exit()>>>, but different things are tried when the
    Security Manager prevents this) unless the <<<net.sf.ehcache.offheap.DoNotHaltOnCriticalAllocationDelay>>> system
    property is set to true.

    This mechanism was built in because allocating a off-heap buffer too large to fit in RAM can quickly and easily
    deplete critical system resources like RAM and swap space and crash the host operating system. Linux and Mac OS X
    will crash in these circumstances.


*   FAQ

**   The DiskStore  Access stripes configuration no longer has effect. Why?

    This has been reimplemented for Ehcache Enterprise and will get added back into the core in the future.


**  What Eviction Algorithms are supported?

    The pluggable MemoryStore eviction algorithms work as normal. The OffHeapStore and DiskStore use a
    Clock Cache,a standard paging algorithm which is an approximation of LRU.

**  Why do I see performance slow down and speed up in a cyclical pattern when I am filling a cache?

    This is due to repartitioning in the OffHeapStore which is normal. Once the cache is fully filled
    the performance slow downs cease.

**  What is the maximum serialized size of an object when using OffHeapStore?

    Firstly, the MemoryStore and the DiskStore do not have any limits.

    By default, the OffHeapStore has a 4MB limit for classes with high quality hashcodes, and
    256KB for those with pathologically bad hashcodes. The built-in classes such as the
    <<<java.lang.Number>>> subclasses such as Long, Integer etc and and <<<String>>> have
    high quality hashcodes.

    You can increase the size by setting a system property cache_name.maxOffHeapValueSize to
    the size you require.

    e.g. com.company.domain.State.maxOffHeapValueSize=30MB


