{Java EE Servlet Caching}

* {CachingFilter}

    You want to use the BlockingCache with web pages, but the requirement to always release the lock creates gnarly code.
    You also want to think about what you are doing withs involved. This is on every jsp:include and every Servlet. And you can
    programmatically add your own. If you have content generated by JSP, Velocity, FreeMarker, String Template, XSLT, Servlet output or anything else,
    it can all be cached by CachingFilter. A separation of concerns.

    How do you determine what the key of a page is? The filter has an abstract calculateKey method, so it is up to you.

    You notice a problem and an opportunity. The problem is that the web pages you are caching are huge. That chews up
    either a lot of memory (Memoryout thinking about the caching.

    Enter the CachingFilter, a Servlet 2.5 compliant filter. Why not just do a JSP tag library, like OSCache? The answer
    is that you want the caching of your responses to be independent of the rendering technology. The filter chain is
    reexcuted every time a RequestDispatcher iStore) or a lot of disk space (DiskStore). Also you notive that these pages take their
    time going over the Internet. The opportunity is that you notice that all modern browsers support gzip encoding. A survey
    of logs reveals that 85% of the time the browser accepts gzipping. (The majority of the 15% that does not is IE
    behind a proxy). Ok, so gzip the response before caching it. Ungzipping is fast - so just ungzip for the 15% of the
    time the browser does not accept gzipping.

    Pages are stored based on the key determined by a <<<calculateKey>>> method. This method enables implementations
    to exclude referral query parameters which have no bearing on the result to be returned.


* Read Behind Configuration

    The CachingFilter queues multiple requests for the same key, so that the downsteam infrastructure only has to
    do the work once.

    By default the request which hits an empty cache element, or an expired one, has to wait while the downstream
    processing occurs. Optionally the <<<readBehind>>> filter initalisation paramter can be configured to true
    which will cause a refresh to occur when the cache is three quarters through it's time to live. This feature
    is only available with HTTP 1.1 Keep Alives disabled. Turning it off is application server specific.
    The mechanism for a few of the application servers is:

** Disable Keep-Alives in Glassfish

    In the domain.xml, set the <<<timeout-in-seconds>>> attribute in the <<<keep-alive element>>> to <<<0>>>.

---
   <keep-alive max-connections="250" thread-count="1" timeout-in-seconds="0"/>
---

** Disable Keep-Alives in Tomcat

---
    <Connector port="9080" protocol="HTTP/1.1"
               maxThreads="150" connectionTimeout="20000"
               redirectPort="9082" maxKeepAliveRequests="1" />
---

** Disable Keep-Alives in Orion

   Change config/default-web-site.xml as follows:

---
   <web-site host="[ALL]" port="9080" display-name="Jaguar WebSite" use-keep-alives="false">
---


* {SimplePageCachingFilter}

    What if you just want to get started with the CachingFilter and don't want to think too hard? Just use SimplePageCachingFilter
    which has a calculateKey method already implemented.

    It uses <<<httpRequest.getRequestURI()).append(httpRequest.getQueryString()>>> for the key. This works most of the time. It tends to get less effective when referrals and affiliates are added to the query,
    which is the case for a lot of e-commerce sites.

    SimplePageCachingFilter is 10 lines of code.
    
    If you use this default implementation, the cache name is called "SimplePageCachingFilter". You need to define a cache with that
     name in ehcache.xml.


* {PageFragmentCachingFilter}

    You notice that an entire page cannot be cached because the data on it vary in staleness. Say, an address which changes
    very infrequently, and the price and availability of inventory, which changes quite a lot. Or you have a portal, with
    lots of components and with different stalenesses. Or you use the replicated cache functionality in ehcache and you
    only want to rebuild the part of the page that got invalidated.

    Enter the PageFragmentCachingFilter. It does everyting that SimplePageCachingFilter does, except it never
    gzips, so the fragments can be combined.


* {SimplePageFragmentCachingFilter}

    What if you just want to get started with the PageFragmentCachingFilter and don't want to think too hard? Just use SimplePageFragmentCachingFilter
    which has a calculateKey method already implemented. It uses <<<httpRequest.getRequestURI()).append(httpRequest.getQueryString()>>>
    for the key. This works most of the time. It tends to get less effective when referrals and affiliates are added to the query,
    which is the case for a lot of e-commerce sites.

    SimplePageFragmentCachingFilter is 10 lines of code.

